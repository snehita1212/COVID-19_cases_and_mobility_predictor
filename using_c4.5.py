# -*- coding: utf-8 -*-
"""Assignment 2 - C4.5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YnHtUE9yi3fqnq-kdkjOIJfIkaHq8v88

**TEAM MEMBERS:**
1. Rimjhim Agarwal   (2020UCH0013)
2. Sheetal Sharma    (2020UCH0014)
3. Snehita Debnath   (2020UCS0094)
4. Himani Khobragade (2020UCS0116)
5. Vartika Vaish     (2020UEE0139)
"""

#Importing essential libraries
import pandas as pd
import numpy as np

df1 = pd.read_csv('/content/changes-visitors-covid_final - changes-visitors-covid_final.csv')
df2 = pd.read_csv('/content/covid-data - covid-data.csv')

"""**DATA PREPROCESSING**"""

india_df1 = df1[df1['Entity'] == "India"]
india_df2 = df2[df2['iso_code'] =='IND']

india_df1.reset_index(inplace = True)
india_df2.reset_index(inplace = True)

india_df1.drop(['index'], axis=1, inplace = True)
india_df2.drop(['index'], axis=1, inplace = True)

india_df2.drop(india_df2.columns[6:], axis=1, inplace = True)

india_df2 = india_df2[18: -2]
india_df2.reset_index(inplace = True)

#Creating a new dataframe
final_df = pd.concat([india_df1, india_df2['new_cases']], axis=1, join='inner')

final_df = final_df.iloc[:, 3:]

#Normalization
for i in final_df.columns:
  final_df[i] = (final_df[i] - final_df[i].min())/(final_df[i].max() - final_df[i].min())

"""**C4.5**"""

class C4_5:
    def fit(self, X, y, min_leaf = 5):
        self.dtree = Node(X, y, np.array(np.arange(len(y))), min_leaf)
        return self

    def predict(self, X):
        return self.dtree.predict(X.values)

class Node:
    def __init__(self, x, y, idxs, min_leaf=5):
        self.x = x
        self.y = y
        self.idxs = idxs
        self.min_leaf = min_leaf
        self.row_count = len(idxs)
        self.col_count = x.shape[1]
        self.val = np.mean(y[idxs])
        self.score = float('inf')
        self.find_varsplit()

    def find_varsplit(self):
        for c in range(self.col_count): self.find_better_split(c)
        if self.is_leaf: return
        x = self.split_col
        lhs = x <= self.split
        rhs = x > self.split
        self.lhs = Node(self.x, self.y, self.idxs[lhs], self.min_leaf)
        self.rhs = Node(self.x, self.y, self.idxs[rhs], self.min_leaf)

    def find_better_split(self, var_idx):
        x = self.x.values[self.idxs, var_idx]

        for r in range(self.row_count):
            lhs = x <= x[r]
            rhs = x > x[r]
            if rhs.sum() < self.min_leaf or lhs.sum() < self.min_leaf: continue

            curr_score = self.find_score(lhs, rhs)
            if curr_score < self.score:
                self.var_idx = var_idx
                self.score = curr_score
                self.split = x[r]

    def find_score(self, lhs, rhs):
        y = self.y[self.idxs]
        lhs_std = y[lhs].std()
        rhs_std = y[rhs].std()
        return lhs_std * lhs.sum() + rhs_std * rhs.sum()

    @property
    def split_col(self): return self.x.values[self.idxs,self.var_idx]

    @property
    def is_leaf(self): return self.score == float('inf')

    def predict(self, x):
        return np.array([self.predict_row(xi) for xi in x])

    def predict_row(self, xi):
        if self.is_leaf: return self.val
        node = self.lhs if xi[self.var_idx] <= self.split else self.rhs
        return node.predict_row(xi)

"""**Creating Training and Testing Data Sets**

**c) Using all mobilities to predict new cases**
"""

df_2 = final_df.copy()
train = df_2.sample(frac=0.80,axis='rows')
test = df_2.sample(frac=0.2,axis='rows')
train = train.reset_index()
test = test.reset_index()
train.drop(['index'],axis=1,inplace=True)
test.drop(['index'],axis=1,inplace=True)

X_train = train.iloc[:,:-1]
X_test = test.iloc[:,:-1]

y_train = train.iloc[:,-1]
y_test = test.iloc[:,-1]

model = C4_5().fit(X_train, y_train)
test = model.predict(X_test)
test

RMSE = np.sqrt(np.sum(((y_test-test)**2)/len(y_test)))   #Room Mean Squared Error
RMSE

MSE = np.sum(((y_test-test)**2)/len(y_test))  #Mean Squared Error
MSE

"""**b) Predicting new cases from mobility i.e., residential (3)**"""

df_2 = final_df.copy()
train = df_2.sample(frac=0.80,axis='rows')
test = df_2.sample(frac=0.2,axis='rows')
train = train.reset_index()
test = test.reset_index()
train.drop(['index'],axis=1,inplace=True)
test.drop(['index'],axis=1,inplace=True)

X_train = train.iloc[:,:-1]
X_test = test.iloc[:,:-1]

y_train = train.iloc[:,-1]
y_test = test.iloc[:,-1]

#Setting all features except 'residential' mobility as zero
columns = ['retail_and_recreation',	'grocery_and_pharmacy',	'transit_stations',	'parks',	'workplaces'	]
for i in columns:
  train.loc[train[i] != 0.0, i] = 0.0
  test.loc[test[i] != 0.0, i] = 0.0

model2 = C4_5().fit(X_train, y_train)
test2 = model2.predict(X_test)
test2

RMSE2 = np.sqrt(np.sum(((y_test-test2)**2)/len(y_test)))   #Room Mean Squared Error
RMSE2

MSE2 = np.sum(((y_test-test2)**2)/len(y_test))  #Mean Squared Error
MSE2

"""**a) Predicting mobility i.e., residential (3) from new cases**"""

df_3 = final_df.copy()
train = df_3.sample(frac=0.80,axis='rows')
test = df_3.sample(frac=0.2,axis='rows')
train = train.reset_index()
test = test.reset_index()
train.drop(['index'],axis=1,inplace=True)
test.drop(['index'],axis=1,inplace=True)

X_train = train[['retail_and_recreation',	'grocery_and_pharmacy',	'transit_stations',	'parks',	'workplaces','new_cases']	]
X_test = test[['retail_and_recreation',	'grocery_and_pharmacy',	'transit_stations',	'parks',	'workplaces','new_cases']]

y_train = train.iloc[:,-5]
y_test = test.iloc[:,-5]

#Setting all features except new_cases as zero
columns = ['retail_and_recreation',	'grocery_and_pharmacy',	'transit_stations',	'parks',	'workplaces'	]
for i in columns:
  train.loc[train[i] != 0.0, i] = 0.0
  test.loc[test[i] != 0.0, i] = 0.0

model3 = C4_5().fit(X_train, y_train)
test3 = model3.predict(X_test)
test3

RMSE3 = np.sqrt(np.sum(((y_test-test3)**2)/len(y_test)))  #Room Mean Squared Error
RMSE3

MSE3 = np.sum(((y_test-test3)**2)/len(y_test))  #Mean Squared Error
MSE3